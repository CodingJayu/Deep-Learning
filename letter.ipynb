{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "column=['letter','x-box','y-box','width','height','onpix','x-bar','v-bar','x2bar','y2bar','xybar','x2ybr','xy2br','x-ege','xegvy','y-ege','yegvx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"/home/kali/Documents/lp/dl/Dataset/letter-recognition.data\",names=column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>x-box</th>\n",
       "      <th>y-box</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>x-bar</th>\n",
       "      <th>v-bar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybr</th>\n",
       "      <th>xy2br</th>\n",
       "      <th>x-ege</th>\n",
       "      <th>xegvy</th>\n",
       "      <th>y-ege</th>\n",
       "      <th>yegvx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>C</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>T</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      letter  x-box  y-box  width  height  onpix  x-bar  v-bar  x2bar  y2bar  \\\n",
       "0          T      2      8      3       5      1      8     13      0      6   \n",
       "1          I      5     12      3       7      2     10      5      5      4   \n",
       "2          D      4     11      6       8      6     10      6      2      6   \n",
       "3          N      7     11      6       6      3      5      9      4      6   \n",
       "4          G      2      1      3       1      1      8      6      6      6   \n",
       "...      ...    ...    ...    ...     ...    ...    ...    ...    ...    ...   \n",
       "19995      D      2      2      3       3      2      7      7      7      6   \n",
       "19996      C      7     10      8       8      4      4      8      6      9   \n",
       "19997      T      6      9      6       7      5      6     11      3      7   \n",
       "19998      S      2      3      4       2      1      8      7      2      6   \n",
       "19999      A      4      9      6       6      2      9      5      3      1   \n",
       "\n",
       "       xybar  x2ybr  xy2br  x-ege  xegvy  y-ege  yegvx  \n",
       "0          6     10      8      0      8      0      8  \n",
       "1         13      3      9      2      8      4     10  \n",
       "2         10      3      7      3      7      3      9  \n",
       "3          4      4     10      6     10      2      8  \n",
       "4          6      5      9      1      7      5     10  \n",
       "...      ...    ...    ...    ...    ...    ...    ...  \n",
       "19995      6      6      4      2      8      3      7  \n",
       "19996     12      9     13      2      9      3      7  \n",
       "19997     11      9      5      2     12      2      4  \n",
       "19998     10      6      8      1      9      5      8  \n",
       "19999      8      1      8      2      7      2      8  \n",
       "\n",
       "[20000 rows x 17 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop(['letter'],axis=1).values\n",
    "y=df['letter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        T\n",
       "1        I\n",
       "2        D\n",
       "3        N\n",
       "4        G\n",
       "        ..\n",
       "19995    D\n",
       "19996    C\n",
       "19997    T\n",
       "19998    S\n",
       "19999    A\n",
       "Name: letter, Length: 20000, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing \n",
    "x_train=x_train/255\n",
    "x_test=x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder=LabelEncoder()\n",
    "y_train=encoder.fit_transform(y_train)\n",
    "y_test=encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-29 15:27:29.124405: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-29 15:27:29.231594: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-29 15:27:29.233606: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-29 15:27:31.773381: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               8704      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 26)                6682      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 146,714\n",
      "Trainable params: 146,714\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(512,activation=\"relu\",input_shape=(x_train[0].shape)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(26,activation='softmax'))\n",
    "model.compile(optimizer='adam',loss=\"sparse_categorical_crossentropy\",metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "125/125 [==============================] - 5s 20ms/step - loss: 3.1309 - accuracy: 0.1429 - val_loss: 2.7653 - val_accuracy: 0.2138\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 2.4113 - accuracy: 0.2907 - val_loss: 2.1388 - val_accuracy: 0.4020\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 2s 18ms/step - loss: 2.0394 - accuracy: 0.3834 - val_loss: 1.8171 - val_accuracy: 0.4880\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.8180 - accuracy: 0.4509 - val_loss: 1.6226 - val_accuracy: 0.5393\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 1.6574 - accuracy: 0.4954 - val_loss: 1.5071 - val_accuracy: 0.5648\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.5641 - accuracy: 0.5262 - val_loss: 1.4273 - val_accuracy: 0.5997\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 1.4854 - accuracy: 0.5571 - val_loss: 1.3502 - val_accuracy: 0.6072\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 1.4171 - accuracy: 0.5741 - val_loss: 1.3004 - val_accuracy: 0.6175\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.3633 - accuracy: 0.5932 - val_loss: 1.2550 - val_accuracy: 0.6320\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.3035 - accuracy: 0.6162 - val_loss: 1.1882 - val_accuracy: 0.6550\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.2569 - accuracy: 0.6246 - val_loss: 1.1649 - val_accuracy: 0.6547\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.2076 - accuracy: 0.6388 - val_loss: 1.1134 - val_accuracy: 0.6662\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.1780 - accuracy: 0.6487 - val_loss: 1.0821 - val_accuracy: 0.6802\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 1.1274 - accuracy: 0.6683 - val_loss: 1.0367 - val_accuracy: 0.6927\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 1.0935 - accuracy: 0.6740 - val_loss: 0.9972 - val_accuracy: 0.7110\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 1.0665 - accuracy: 0.6858 - val_loss: 0.9679 - val_accuracy: 0.7190\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.0359 - accuracy: 0.6918 - val_loss: 0.9337 - val_accuracy: 0.7268\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.0118 - accuracy: 0.6943 - val_loss: 0.9091 - val_accuracy: 0.7275\n",
      "Epoch 19/50\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 0.9820 - accuracy: 0.7079 - val_loss: 0.8788 - val_accuracy: 0.7387\n",
      "Epoch 20/50\n",
      "125/125 [==============================] - 2s 18ms/step - loss: 0.9569 - accuracy: 0.7137 - val_loss: 0.8583 - val_accuracy: 0.7487\n",
      "Epoch 21/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 0.9352 - accuracy: 0.7155 - val_loss: 0.8421 - val_accuracy: 0.7460\n",
      "Epoch 22/50\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.9055 - accuracy: 0.7270 - val_loss: 0.8221 - val_accuracy: 0.7592\n",
      "Epoch 23/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 0.8882 - accuracy: 0.7327 - val_loss: 0.8005 - val_accuracy: 0.7605\n",
      "Epoch 24/50\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.8694 - accuracy: 0.7371 - val_loss: 0.7764 - val_accuracy: 0.7665\n",
      "Epoch 25/50\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.8499 - accuracy: 0.7421 - val_loss: 0.7816 - val_accuracy: 0.7707\n",
      "Epoch 26/50\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.8308 - accuracy: 0.7485 - val_loss: 0.7456 - val_accuracy: 0.7840\n",
      "Epoch 27/50\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.8119 - accuracy: 0.7542 - val_loss: 0.7228 - val_accuracy: 0.7795\n",
      "Epoch 28/50\n",
      "125/125 [==============================] - 2s 19ms/step - loss: 0.7892 - accuracy: 0.7599 - val_loss: 0.7092 - val_accuracy: 0.7903\n",
      "Epoch 29/50\n",
      "125/125 [==============================] - 4s 31ms/step - loss: 0.7790 - accuracy: 0.7620 - val_loss: 0.6883 - val_accuracy: 0.7950\n",
      "Epoch 30/50\n",
      "125/125 [==============================] - 3s 25ms/step - loss: 0.7660 - accuracy: 0.7657 - val_loss: 0.6794 - val_accuracy: 0.7958\n",
      "Epoch 31/50\n",
      "125/125 [==============================] - 3s 25ms/step - loss: 0.7522 - accuracy: 0.7701 - val_loss: 0.6609 - val_accuracy: 0.8065\n",
      "Epoch 32/50\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.7295 - accuracy: 0.7763 - val_loss: 0.6580 - val_accuracy: 0.8050\n",
      "Epoch 33/50\n",
      "125/125 [==============================] - 3s 23ms/step - loss: 0.7194 - accuracy: 0.7822 - val_loss: 0.6412 - val_accuracy: 0.8035\n",
      "Epoch 34/50\n",
      "125/125 [==============================] - 3s 25ms/step - loss: 0.7097 - accuracy: 0.7786 - val_loss: 0.6302 - val_accuracy: 0.8125\n",
      "Epoch 35/50\n",
      "125/125 [==============================] - 3s 20ms/step - loss: 0.6947 - accuracy: 0.7846 - val_loss: 0.6166 - val_accuracy: 0.8180\n",
      "Epoch 36/50\n",
      "125/125 [==============================] - 2s 18ms/step - loss: 0.6839 - accuracy: 0.7859 - val_loss: 0.6007 - val_accuracy: 0.8180\n",
      "Epoch 37/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 0.6783 - accuracy: 0.7901 - val_loss: 0.5908 - val_accuracy: 0.8267\n",
      "Epoch 38/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 0.6635 - accuracy: 0.7968 - val_loss: 0.5827 - val_accuracy: 0.8285\n",
      "Epoch 39/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 0.6566 - accuracy: 0.7967 - val_loss: 0.5738 - val_accuracy: 0.8267\n",
      "Epoch 40/50\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 0.6446 - accuracy: 0.8001 - val_loss: 0.5619 - val_accuracy: 0.8292\n",
      "Epoch 41/50\n",
      "125/125 [==============================] - 2s 18ms/step - loss: 0.6308 - accuracy: 0.8042 - val_loss: 0.5389 - val_accuracy: 0.8400\n",
      "Epoch 42/50\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 0.6224 - accuracy: 0.8058 - val_loss: 0.5331 - val_accuracy: 0.8425\n",
      "Epoch 43/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 0.6062 - accuracy: 0.8106 - val_loss: 0.5228 - val_accuracy: 0.8465\n",
      "Epoch 44/50\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 0.6034 - accuracy: 0.8109 - val_loss: 0.5190 - val_accuracy: 0.8457\n",
      "Epoch 45/50\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.5947 - accuracy: 0.8134 - val_loss: 0.5049 - val_accuracy: 0.8485\n",
      "Epoch 46/50\n",
      "125/125 [==============================] - 2s 18ms/step - loss: 0.5812 - accuracy: 0.8182 - val_loss: 0.5014 - val_accuracy: 0.8547\n",
      "Epoch 47/50\n",
      "125/125 [==============================] - 3s 24ms/step - loss: 0.5719 - accuracy: 0.8223 - val_loss: 0.4861 - val_accuracy: 0.8537\n",
      "Epoch 48/50\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.5663 - accuracy: 0.8255 - val_loss: 0.4879 - val_accuracy: 0.8580\n",
      "Epoch 49/50\n",
      "125/125 [==============================] - 3s 23ms/step - loss: 0.5618 - accuracy: 0.8244 - val_loss: 0.4807 - val_accuracy: 0.8633\n",
      "Epoch 50/50\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.5525 - accuracy: 0.8266 - val_loss: 0.4598 - val_accuracy: 0.8633\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff54c655190>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=50,batch_size=128,verbose=1,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n",
       "       'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M','N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 1s 3ms/step\n",
      "Z\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Z'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre=model.predict(x_test)\n",
    "val=np.argmax(pre[0])\n",
    "print(classes[val])\n",
    "classes[y_test[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 1s 4ms/step - loss: 0.4598 - accuracy: 0.8633\n",
      "Loss: 0.45984289050102234\n",
      "Accuracy (test data): 86.32500171661377\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy=model.evaluate(x_test,y_test)\n",
    "print(\"Loss:\",loss)\n",
    "print(\"Accuracy (test data):\",accuracy*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
